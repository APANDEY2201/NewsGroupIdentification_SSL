{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "01_newsgroup_Preprocessingpipeline.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5X_iA6JfUuf"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors, datasets\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYF7OGwsfUuh"
      },
      "source": [
        "#load data\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',shuffle=True, remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqNfC4uRfUui"
      },
      "source": [
        "def filter_data():\n",
        "    #filter data\n",
        "    # newsgroups_train = fetch_20newsgroups(subset='train',remove=('headers', 'footers', 'quotes'))\n",
        "    # newsgroups_test = fetch_20newsgroups(subset='test',remove=('headers', 'footers', 'quotes'))\n",
        "    \n",
        "    class_names = newsgroups_train.target_names\n",
        "    print('Training data size::', len(newsgroups_train['data']))\n",
        "    \n",
        "    # Printing all the categories\n",
        "    print('Training categories names::', newsgroups_train.target_names)\n",
        "    \n",
        "    # Finding frequency of each category\n",
        "    targets, frequency = np.unique(newsgroups_train.target, return_counts=True)\n",
        "    targets_str = np.array(newsgroups_train.target_names)\n",
        "    \n",
        "    #Prinnting all frequency\n",
        "    #print(\"Print targets, frequency in array::\", targets, frequency)\n",
        "    print(list(zip(targets_str, frequency)))\n",
        "    \n",
        "    #Training data class distribution\n",
        "    #fig=plt.figure(figsize=(10, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
        "    #plt.bar(targets_str,frequency, color='#ff6961')\n",
        "    #plt.xticks(rotation=90)\n",
        "    #plt.title('Class distribution of 20 Newsgroups Training Data')\n",
        "    #plt.xlabel('News Group')\n",
        "    #plt.ylabel('Frequency')\n",
        "    #plt.show()\n",
        "    \n",
        "    # Preparing train data\n",
        "    newsgroups_train_df = pd.DataFrame({'data': newsgroups_train.data, 'target': newsgroups_train.target})\n",
        "    #print(newsgroups_train_df.head())\n",
        "    # Preparing test data\n",
        "    newsgroups_test_df = pd.DataFrame({'data': newsgroups_test.data, 'target': newsgroups_test.target})\n",
        "    print(newsgroups_test_df)\n",
        "    \n",
        "    # Text preprocessing steps - remove numbers, captial letters and punctuation\n",
        "    newsgroups_train_df.data.str.replace('[^a-zA-Z]', '')\n",
        "    newsgroups_test_df.data.str.replace('[^a-zA-Z]', '')\n",
        "    newsgroups_train_df = newsgroups_train_df.data.str.lower()\n",
        "    newsgroups_test_df = newsgroups_test_df.data.str.lower()\n",
        "    print(newsgroups_train_df.head())\n",
        "    \n",
        "\n",
        "    return newsgroups_train, newsgroups_test, class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJnxHtDfUuk"
      },
      "source": [
        "def bow_features(train_data, test_data):\n",
        "    # Bag-of-words representation\n",
        "    bow_vectorize = CountVectorizer()\n",
        "    bow_train = bow_vectorize.fit_transform(train_data.data) #bag-of-word features for training data\n",
        "    bow_test = bow_vectorize.transform(test_data.data)\n",
        "    feature_names = bow_vectorize.get_feature_names() #converts feature index to the word it represents.\n",
        "    shape = bow_train.shape\n",
        "    print('{} train data points.'.format(shape[0]))\n",
        "    print('{} feature dimension.'.format(shape[1]))\n",
        "    print('Most common word in training set is \"{}\"'.format(feature_names[bow_train.sum(axis=0).argmax()]))\n",
        "    return bow_train, bow_test, feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jArBOqOefUuk"
      },
      "source": [
        "def tf_idf_features(train_data, test_data):\n",
        "    # Bag-of-words representation\n",
        "    tf_idf_vectorize = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
        "    tf_idf_train = tf_idf_vectorize.fit_transform(train_data.data) #bag-of-word features for training data\n",
        "    feature_names = tf_idf_vectorize.get_feature_names() #converts feature index to the word it represents.\n",
        "    tf_idf_test = tf_idf_vectorize.transform(test_data.data)\n",
        "    print(tf_idf_train)\n",
        "    return tf_idf_train, tf_idf_test, feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfN7_RfCfUul",
        "outputId": "8efb5ed5-cb1c-46fd-8483-304e687885e2"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    train_data, test_data, class_names = filter_data()\n",
        "\n",
        "    #Count Vectorization\n",
        "    train_bow, test_bow, feature_names = bow_features(train_data, test_data)\n",
        "    \n",
        "    # TF-idf\n",
        "    train_bow_tf_idf, test_bow_tf_idf, feature_names_tf_idf = tf_idf_features(train_data, test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size:: 11314\n",
            "Training categories names:: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "[('alt.atheism', 480), ('comp.graphics', 584), ('comp.os.ms-windows.misc', 591), ('comp.sys.ibm.pc.hardware', 590), ('comp.sys.mac.hardware', 578), ('comp.windows.x', 593), ('misc.forsale', 585), ('rec.autos', 594), ('rec.motorcycles', 598), ('rec.sport.baseball', 597), ('rec.sport.hockey', 600), ('sci.crypt', 595), ('sci.electronics', 591), ('sci.med', 594), ('sci.space', 593), ('soc.religion.christian', 599), ('talk.politics.guns', 546), ('talk.politics.mideast', 564), ('talk.politics.misc', 465), ('talk.religion.misc', 377)]\n",
            "                                                   data  target\n",
            "0     I am a little confused on all of the models of...       7\n",
            "1     I'm not familiar at all with the format of the...       5\n",
            "2                                   \\nIn a word, yes.\\n       0\n",
            "3     \\nThey were attacking the Iraqis to drive them...      17\n",
            "4     \\nI've just spent two solid months arguing tha...      19\n",
            "...                                                 ...     ...\n",
            "7527  \\n   Henry, if I read you correctly, you may b...      14\n",
            "7528  about\\nthem on\\n\\nActually, I thought Macs wer...       4\n",
            "7529  I sent a version of this post out a while ago,...       9\n",
            "7530  I have this kit which includes the following :...       6\n",
            "7531  \\nFine, but one of the points of this entire d...      15\n",
            "\n",
            "[7532 rows x 2 columns]\n",
            "0    i was wondering if anyone out there could enli...\n",
            "1    a fair number of brave souls who upgraded thei...\n",
            "2    well folks, my mac plus finally gave up the gh...\n",
            "3    \\ndo you have weitek's address/phone number?  ...\n",
            "4    from article <c5owcb.n3p@world.std.com>, by to...\n",
            "Name: data, dtype: object\n",
            "11314 train data points.\n",
            "101631 feature dimension.\n",
            "Most common word in training set is \"the\"\n",
            "  (0, 1078077)\t0.10879060524157366\n",
            "  (0, 765307)\t0.10879060524157366\n",
            "  (0, 920249)\t0.10879060524157366\n",
            "  (0, 866050)\t0.10879060524157366\n",
            "  (0, 376275)\t0.10879060524157366\n",
            "  (0, 1396516)\t0.10879060524157366\n",
            "  (0, 1957477)\t0.10879060524157366\n",
            "  (0, 1646288)\t0.10879060524157366\n",
            "  (0, 656910)\t0.10879060524157366\n",
            "  (0, 1170112)\t0.10879060524157366\n",
            "  (0, 1733022)\t0.10879060524157366\n",
            "  (0, 1005634)\t0.10879060524157366\n",
            "  (0, 331432)\t0.10879060524157366\n",
            "  (0, 1498315)\t0.10879060524157366\n",
            "  (0, 1581503)\t0.10879060524157366\n",
            "  (0, 354312)\t0.10879060524157366\n",
            "  (0, 189412)\t0.10879060524157366\n",
            "  (0, 1622091)\t0.10879060524157366\n",
            "  (0, 1457116)\t0.10879060524157366\n",
            "  (0, 611020)\t0.10879060524157366\n",
            "  (0, 344547)\t0.10879060524157366\n",
            "  (0, 367650)\t0.10879060524157366\n",
            "  (0, 132210)\t0.10879060524157366\n",
            "  (0, 628990)\t0.10879060524157366\n",
            "  (0, 120613)\t0.10879060524157366\n",
            "  :\t:\n",
            "  (11313, 1652805)\t0.08215954049608792\n",
            "  (11313, 1721533)\t0.09002229009461027\n",
            "  (11313, 79535)\t0.09002229009461027\n",
            "  (11313, 1347439)\t0.0700464370740321\n",
            "  (11313, 1162570)\t0.06969737722986967\n",
            "  (11313, 285428)\t0.07595979471576327\n",
            "  (11313, 1299835)\t0.0857719362710768\n",
            "  (11313, 1673671)\t0.07240180455995147\n",
            "  (11313, 1605328)\t0.07040658001614854\n",
            "  (11313, 327957)\t0.06174901552796744\n",
            "  (11313, 1779495)\t0.06464865532953687\n",
            "  (11313, 1902502)\t0.05410152001366118\n",
            "  (11313, 1582835)\t0.07429679089756556\n",
            "  (11313, 1582718)\t0.060012590418797515\n",
            "  (11313, 1586791)\t0.06709759593577902\n",
            "  (11313, 874298)\t0.06935873865410537\n",
            "  (11313, 366932)\t0.060613713826311616\n",
            "  (11313, 1800072)\t0.05310364185219398\n",
            "  (11313, 78640)\t0.09480999006845502\n",
            "  (11313, 824648)\t0.05017351825935625\n",
            "  (11313, 855946)\t0.040668044288641084\n",
            "  (11313, 31480)\t0.046681934188214\n",
            "  (11313, 1066869)\t0.04032745023185114\n",
            "  (11313, 1240259)\t0.08637862971350635\n",
            "  (11313, 656539)\t0.06076910735022431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq-0zpIpfUum"
      },
      "source": [
        "#Ruksar"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}